{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbeb6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "import torchvision\n",
    "import pickle\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.data import Metadata\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from detectron2.modeling import build_model\n",
    "import detectron2.data.transforms as T\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b53fb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This is where you will set all the relevant config file and weight file variables'''\n",
    "CONFIG_FILE = \"\" # Training specific config file for fathomnet\n",
    "WEIGHTS_FILE = \"\" # path to the model with fathomnet weights\n",
    "NMS_THRESH = 0.45 # This is where you can set an nms threshold for the all boxes results\n",
    "SCORE_THRESH = 0.3 # This is where you can set the model score threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85c486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fathomnet_metadata = Metadata(\n",
    "    name='fathomnet_val',\n",
    "    thing_classes=[\n",
    "         'Anemone',\n",
    "         'Fish',\n",
    "         'Eel',\n",
    "         'Gastropod',\n",
    "         'Sea star',\n",
    "         'Feather star',\n",
    "         'Sea cucumber',\n",
    "         'Urchin',\n",
    "         'Glass sponge',\n",
    "         'Sea fan',\n",
    "         'Soft coral',\n",
    "         'Sea pen',\n",
    "         'Stony coral',\n",
    "         'Ray',\n",
    "         'Crab',\n",
    "         'Shrimp',\n",
    "         'Squat lobster',\n",
    "         'Flatfish',\n",
    "         'Sea spider',\n",
    "         'Worm']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7997a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is where the model parameters are instantiated. There is a LOT of nested arguments in these yaml files, \n",
    "and the merging of baseline defaults plus dataset specific parameters.\n",
    "'''\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_50_FPN_3x.yaml\"))\n",
    "cfg.merge_from_file(CONFIG_FILE)\n",
    "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = SCORE_THRESH\n",
    "cfg.MODEL.WEIGHTS = WEIGHTS_FILE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed08948",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loading of the model weights, but more importantly this is where the model is actually instantiated as something that \n",
    "can take inputs and provide outputs. There is a lot of documentation about this, but not much in the way of \n",
    "straightforward tutorials.\n",
    "'''\n",
    "\n",
    "model = build_model(cfg)  # returns a torch.nn.Module\n",
    "checkpointer = DetectionCheckpointer(model)\n",
    "checkpointer.load(cfg.MODEL.WEIGHTS)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9176ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is where you can specify how to resize an image. There are two examples here, be aware of which one you are\n",
    "calling later when preprocessing an image.\n",
    "'''\n",
    "aug = T.ResizeShortestEdge(\n",
    "        short_edge_length=[cfg.INPUT.MIN_SIZE_TEST], max_size=cfg.INPUT.MAX_SIZE_TEST, sample_style=\"choice\"\n",
    "    )\n",
    "aug1 = T.ResizeShortestEdge(\n",
    "            short_edge_length=[1080], max_size=1980, sample_style=\"choice\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2ccfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We use a separate NMS layer because initially detectron only does nms intra class, so we want to do nms on all boxes.\n",
    "'''\n",
    "post_process_nms = torchvision.ops.nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19356ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IMAGE = \"\" # Path to image you want to run the model on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa63ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load the image, get the height and width, perform augmentation, run the model, perform nms thresholding. Also instantiate\n",
    "a useful object for visualizing the outputs\n",
    "'''\n",
    "\n",
    "im = cv2.imread(TEST_IMAGE)\n",
    "im_height,im_width,_ = im.shape\n",
    "v_inf = Visualizer(im[:, :, ::-1],\n",
    "               metadata=fathomnet_metadata, \n",
    "               scale=1.0, \n",
    "               instance_mode=ColorMode.IMAGE_BW)\n",
    "im = aug1.get_transform(im).apply_image(im)\n",
    "with torch.no_grad():\n",
    "    im = torch.as_tensor(im.astype(\"float32\").transpose(2, 0, 1))\n",
    "    model_outputs = model([{\"image\" : im, \"height\" : im_height, \"width\" : im_width}])[0]\n",
    "\n",
    "model_outputs[\"instances\"] = model_outputs[\"instances\"][post_process_nms(model_outputs[\"instances\"].pred_boxes.tensor, model_outputs[\"instances\"].scores, NMS_THRESH).to(\"cpu\").tolist()]\n",
    "\n",
    "out_inf_raw = v_inf.draw_instance_predictions(model_outputs[\"instances\"].to(\"cpu\"))\n",
    "im_pil_inf_raw = Image.fromarray(out_inf_raw.get_image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1895db",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Visualize the outputs'''\n",
    "plt.figure(figsize=(24,16))\n",
    "plt.imshow(im_pil_inf_raw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

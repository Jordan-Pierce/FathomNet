{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiscale inference\n",
    "Perform inference at two different rescaling factors. This approach can resolve objects that might otherwise be lost when running inference with a single resizing of an input image.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "9fbeb6e7",
    "outputId": "73f50343-a7e9-41e3-d057-fa81f2f35020"
   },
   "outputs": [],
   "source": [
    "import detectron2\n",
    "import torchvision\n",
    "import pickle\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.data import Metadata\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from detectron2.modeling import build_model\n",
    "import detectron2.data.transforms as T\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0b53fb0f"
   },
   "outputs": [],
   "source": [
    "'''This is where you will set all the relevant config file and weight file variables'''\n",
    "CONFIG_FILE = \"\" # Training specific config file for fathomnet\n",
    "WEIGHTS_FILE = \"\" # path to the model with fathomnet weights\n",
    "NMS_THRESH = 0.45 # This is where you can set an nms threshold for the all boxes results\n",
    "SCORE_THRESH = 0.3 # This is where you can set the model score threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d85c486a"
   },
   "outputs": [],
   "source": [
    "fathomnet_metadata = Metadata(\n",
    "    name='fathomnet_val',\n",
    "    thing_classes=[\n",
    "         'Anemone',\n",
    "         'Fish',\n",
    "         'Eel',\n",
    "         'Gastropod',\n",
    "         'Sea star',\n",
    "         'Feather star',\n",
    "         'Sea cucumber',\n",
    "         'Urchin',\n",
    "         'Glass sponge',\n",
    "         'Sea fan',\n",
    "         'Soft coral',\n",
    "         'Sea pen',\n",
    "         'Stony coral',\n",
    "         'Ray',\n",
    "         'Crab',\n",
    "         'Shrimp',\n",
    "         'Squat lobster',\n",
    "         'Flatfish',\n",
    "         'Sea spider',\n",
    "         'Worm']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bb7997a2",
    "outputId": "fec50fb8-b441-4de0-8a7f-0bde9048ae84"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This is where the model parameters are instantiated. There is a LOT of nested arguments in these yaml files, \n",
    "and the merging of baseline defaults plus dataset specific parameters.\n",
    "'''\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_50_FPN_3x.yaml\"))\n",
    "cfg.merge_from_file(CONFIG_FILE)\n",
    "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = SCORE_THRESH\n",
    "cfg.MODEL.WEIGHTS = WEIGHTS_FILE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ed08948",
    "outputId": "8b0bd60c-fcb2-4d2c-9f3a-76e813e10f38"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Loading of the model weights, but more importantly this is where the model is actually instantiated as something that \n",
    "can take inputs and provide outputs. There is a lot of documentation about this, but not much in the way of \n",
    "straightforward tutorials.\n",
    "'''\n",
    "\n",
    "model = build_model(cfg)  # returns a torch.nn.Module\n",
    "checkpointer = DetectionCheckpointer(model)\n",
    "checkpointer.load(cfg.MODEL.WEIGHTS)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9176ce50"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Create two augmentations and make a list to iterate over\n",
    "'''\n",
    "aug1 = T.ResizeShortestEdge(\n",
    "        short_edge_length=[cfg.INPUT.MIN_SIZE_TEST], max_size=cfg.INPUT.MAX_SIZE_TEST, sample_style=\"choice\"\n",
    "    )\n",
    "aug2 = T.ResizeShortestEdge(\n",
    "            short_edge_length=[1080], max_size=1980, sample_style=\"choice\"\n",
    "    )\n",
    "\n",
    "augs = [aug1, aug2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5c2ccfd1"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "We use a separate NMS layer because initially detectron only does nms intra class, so we want to do nms on all boxes.\n",
    "'''\n",
    "post_process_nms = torchvision.ops.nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "19356ab9"
   },
   "outputs": [],
   "source": [
    "TEST_IMAGE = \"\" # Path to image you want to run the model on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "udp9jZllvSdr",
    "outputId": "7be9906f-3f13-4098-db0f-8aaee723c4a5"
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Load the image, get the height and width. Iterate over each augmentation: do the augmentation, run the model, \n",
    "perform nms thresholding, instantiate a useful object for visualizing the outputs. Saves a list of outputs objects\n",
    "'''\n",
    "\n",
    "img = cv2.imread(TEST_IMAGE)\n",
    "im_height,im_width,_ = img.shape\n",
    "v_inf = Visualizer(img[:, :, ::-1],\n",
    "               metadata=fathomnet_metadata, \n",
    "               scale=1.0, \n",
    "               instance_mode=ColorMode.IMAGE_BW)\n",
    "insts = []\n",
    "\n",
    "# iterate over input augmentations\n",
    "for ag in augs:\n",
    "  im = ag.get_transform(img).apply_image(img)\n",
    "  with torch.no_grad():\n",
    "      im = torch.as_tensor(im.astype(\"float32\").transpose(2, 0, 1))\n",
    "      model_outputs = model([{\"image\" : im, \"height\" : im_height, \"width\" : im_width}])[0]\n",
    "  \n",
    "  # populate list with all outputs\n",
    "  for ii in range(len(model_outputs['instances'])):\n",
    "    insts.append(model_outputs['instances'][ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Concatonate the model outputs and run NMS thesholding on all output \n",
    "\"\"\"\n",
    "\n",
    "model_inst = detectron2.structures.instances.Instances([im_height, im_width])  # instantiate a dummy Instance object to concatenate the instances\n",
    "xx = model_inst.cat(insts)[post_process_nms(model_inst.cat(insts).pred_boxes.tensor, model_inst.cat(insts).scores, NMS_THRESH).to(\"cpu\").tolist()]\n",
    "\n",
    "print('Number of predictions:', len(xx))\n",
    "out_inf_raw = v_inf.draw_instance_predictions(xx.to(\"cpu\"))\n",
    "im_pil_inf_raw = Image.fromarray(out_inf_raw.get_image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 939
    },
    "id": "gr4QL3lO5gxl",
    "outputId": "21128871-f127-4e5d-d01e-b46e61ffa8c8"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Display output\n",
    "\"\"\"\n",
    "plt.figure(figsize=(24,16))\n",
    "plt.imshow(im_pil_inf_raw)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Detectron2-Inference-MBARI.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
